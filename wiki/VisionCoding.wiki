#summary FRC 2012 gives several different options for executing machine vision code for target selection.

= Introduction =

The programming sub team has been investigating the various methods by which we can perform machine vision tasks.  The goal is to have the robot identify the parameters necessary for a firing solution.  The turret will use this information to program it's z-axis rotation, hood elevation, and firing velocity.

The vision whitepaper and Chief Delphi give several techniques, but they basically converge as follows:

 #  grab a color image from the onboard Axis camera
 #  create a binary image using a HSL filter
 #  use convex hull algorithms to identify closed polygons
 #  use  scoring  (rectangularity and aspect ratio metrics) to identify the polygons that have a high likelihood of being the four retroreflective tape rectangles on the backboards
 #  based on the skew of the polygons caused by perspective, calculate the distance and angle to the target in order to compute a firing solution.

The processing steps can be accomplished in several ways

 # on the cRio using LabView and the NI Vision Assistant
 # on the cRio using Java and jna wrapped java functions that call the NI Vision C functions
 # on the laptop using the WPI libraries
 # on the laptop using Java and OpenCV

= Laptop - Java - OpenCV =

OpenCV is an Open-Source Computer Vision library.  It is written in C++, but a Google Code project ([http://code.google.com/p/javacv/]) wraps OpenCV c calls into Java.  Using these wrappers, we can call any OpenCV function and use it in our Java code.

Steps for Use:
 #  Install OpenCV for Windows (unpack the ZIP file to the root directory as its default)
 #  Download the JavaCV jar files (copy and store them anywhere)
 #  In NetBeans, create a new Library that points to javacpp.jar, javacv.jar, and javacv-windows-x86.jar
 #  Create a new project, and set the Project -> Libraries preference to the new Library you created in the previous step.
 #  In the project, you can import, for example

{{{
import com.googlecode.javacpp.Loader;
import com.googlecode.javacv.*;
import static com.googlecode.javacv.cpp.opencv_core.*;
import static com.googlecode.javacv.cpp.opencv_imgproc.*;
import static com.googlecode.javacv.cpp.opencv_calib3d.*;
import static com.googlecode.javacv.cpp.opencv_objdetect.*;
}}}

*Note* The WPIImage class uses the opencv IplImage class as its backing store.  The backing store is protected but I saw the idea to write a WPIImage extension that does nothing more than return the IplImage when requested.  That means we can use opencv in our SmartDashboard extensions in the processImage method.

= cRIO - Java - WPI/NiVision libraries =
The Team 399 code is based on the sample targeting code included with the NetBeans plugins.  It takes a ColorImage from the camera, uses a thresholdHSL to produce a BinaryImage.  The BinaryImage is then run through a convex hull, then filtered for particles that are too small.  Each remaining particle is then run through area, rectangularity and aspect ratio scoring.  The results are then presumed to be targets.

*Libraries* The WPI classes, Image, ColorImage, and BinaryImage, use the NIVision c libraries wrapped through the WPI wrappers (NIVision.java).  Image and ColorImage are abstract.  Trying to instantiate an HSLImage or RGBImage (concrete subclasses of ColorImage) results in a lovely stack trace.  Error is the <code>java.lang.ClassCastException: java.lang.String cannot be cast to com.sun.squawk.Address</code>.  I think that it can only be run on the squawk jvm on the crio.

The results were encouraging so far.  In a single target test, the algorithm identified the center of the target within 3 pixels.  Distance was 98% accurate. Tests were conducted at angles from +-45 degrees off of orthogonal from the basket. After that, the results were mixed, and further tests will be required.
